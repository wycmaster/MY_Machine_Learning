{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Sound Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to build up a classification model to distinguish different sound in urban context, which serves as a basis on further study on urban environment. The urban sound dataset is URBANSOUND8K from the Center for Urban Science and Progress (CUSP) at NYU (https://urbansounddataset.weebly.com/urbansound8k.html). \n",
    "\n",
    "This dataset contains 8732 labeled sound excerpts (<=4s) of urban sounds from 10 classes: air_conditioner, car_horn, children_playing, dog_bark, drilling, enginge_idling, gun_shot, jackhammer, siren, and street_music. \n",
    "\n",
    "In order to better understand involved machine learning algorithms(Linear Multiclass SVM, Kernelized Multiclass SVM), all the methods and algorithms are writen by ***numpy*** instead of ***sklearn***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "%matplotlib inline\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "# And the display module for visualization\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiclass linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will try a multiclass linear SVM to conduct the classification.\n",
    "\n",
    "Mel-Frequency Cepstral Coefficients (MFCC) is used to extract features from the audio records. It can be calculated by the module ***librosa***.\n",
    "\n",
    "Use the first 25 MFCC's summary statistics (minimum, maximum, me- dian, mean, variance, skewness, kurtosis and the mean and variance of the first and second derivatives) to form the inputs X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_feacture_generator(y, sr, n_mfcc = 25):\n",
    "    '''\n",
    "    Calculate Mel-Frequency Cepstral Coefficients (MFCC) for certian audio record.\n",
    "    Generate summary statistics and finally get a feature vector of 275 dimensions.\n",
    "    '''\n",
    "    \n",
    "    # Extract the top n_mfcc Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    # Generate summary statistics for the 25 coefficents\n",
    "    ## minimum\n",
    "    mfcc_min = mfcc.min(axis = 1)\n",
    "    ## maximum\n",
    "    mfcc_max = mfcc.max(axis = 1)\n",
    "    ## median\n",
    "    mfcc_med = np.median(mfcc, axis = 1)\n",
    "    ## mean\n",
    "    mfcc_mean = mfcc.mean(axis = 1)\n",
    "    ## variance\n",
    "    mfcc_var = mfcc.var(axis = 1)\n",
    "    ## skewness\n",
    "    mfcc_skew = stats.skew(mfcc, axis = 1)\n",
    "    ## kurtosis\n",
    "    mfcc_kur = stats.kurtosis(mfcc, axis = 1)\n",
    "    ## mean of first derivatives\n",
    "    delta_mfcc  = librosa.feature.delta(mfcc)\n",
    "    mfcc_d1_mean = delta_mfcc.mean(axis = 1)\n",
    "    ## variance of first derivatives\n",
    "    mfcc_d1_var = delta_mfcc.var(axis = 1)\n",
    "    ## mean of second derivatives\n",
    "    delta2_mfcc  = librosa.feature.delta(mfcc, order=2)\n",
    "    mfcc_d2_mean = delta2_mfcc.mean(axis = 1)\n",
    "    ## variance of second derivatives\n",
    "    mfcc_d2_var = delta2_mfcc.var(axis = 1)\n",
    "\n",
    "    # stack features together\n",
    "    M = np.concatenate([mfcc_min, mfcc_max, mfcc_med, mfcc_mean, mfcc_var, mfcc_skew, mfcc_kur, mfcc_d1_mean,\n",
    "                        mfcc_d1_var, mfcc_d2_mean, mfcc_d2_var])\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Load audio records from folders without foldi. Use foldi as validation set.\n",
    "    Would take a long time for running this function.\n",
    "'''\n",
    "def load_witout_i(i):\n",
    "    data_path = \"/Users/chenwangyang/NYU Machine Learning/UrbanSound8K/audio\"\n",
    "    filelist = os.listdir(data_path)\n",
    "    filelist.remove('.DS_Store')\n",
    "    filelist.remove('fold{}'.format(i))\n",
    "    filelist.sort()\n",
    "    class_list = []\n",
    "    y_list = []\n",
    "    sr_list = []\n",
    "    \n",
    "    for fold in filelist:\n",
    "        fold_path = os.path.join(data_path,fold)\n",
    "        fold_filelist = os.listdir(fold_path)\n",
    "        fold_filelist.sort()  \n",
    "        for audio in fold_filelist:\n",
    "            try:\n",
    "                if audio == '.DS_Store':\n",
    "                    continue\n",
    "                else:\n",
    "                    class_index = audio.find('-')+1\n",
    "                    class_list.append(int(audio[class_index]))\n",
    "                    audio_path = os.path.join(fold_path,audio)\n",
    "                    y, sr = librosa.load(audio_path)\n",
    "                    y_list.append(y)\n",
    "                    sr_list.append(sr)\n",
    "            except:\n",
    "                continue\n",
    "    return y_list, sr_list, class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio records from a single folder\n",
    "def load_i(i):\n",
    "    data_path = \"/Users/chenwangyang/NYU Machine Learning/UrbanSound8K/audio/fold{}\".format(i)\n",
    "    filelist = os.listdir(data_path)\n",
    "    class_list = []\n",
    "    y_list = []\n",
    "    sr_list = []\n",
    "    for audio in filelist:\n",
    "        try:\n",
    "            if audio == '.DS_Store':\n",
    "                continue\n",
    "            else:\n",
    "                class_index = audio.find('-')+1\n",
    "                class_list.append(int(audio[class_index]))\n",
    "                audio_path = os.path.join(data_path,audio)\n",
    "                y, sr = librosa.load(audio_path)\n",
    "                y_list.append(y)\n",
    "                sr_list.append(sr)\n",
    "        except:\n",
    "            continue\n",
    "    return y_list, sr_list, class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the algorithm with setting fold10 as validation set. Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate training set X_train and y_train\n",
    "y_list, sr_list, class_list = load_witout_i(10)\n",
    "X_train = np.zeros((len(y_list), 275))\n",
    "for i, (y, sr) in enumerate(zip(y_list, sr_list)):\n",
    "    try:\n",
    "        X_train[i] = mel_feacture_generator(y, sr, n_mfcc = 25)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "y_train = np.array(class_list).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation set X_test and y_test\n",
    "y_list, sr_list, class_list = load_i(10)\n",
    "X_test = np.zeros((len(y_list), 275))\n",
    "for i, (y, sr) in enumerate(zip(y_list, sr_list)):\n",
    "    try:\n",
    "        X_test[i] = mel_feacture_generator(y, sr, n_mfcc = 25)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "y_test = np.array(class_list).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass SVM classifier \n",
    "def zeroOne(y,a) :\n",
    "    '''\n",
    "    Computes the zero-one loss.\n",
    "    @param y: output class\n",
    "    @param a: predicted class\n",
    "    @return 1 if different, 0 if same\n",
    "    '''\n",
    "    return int(y != a)\n",
    "\n",
    "def featureMap(X,y,num_classes) :\n",
    "    '''\n",
    "    Computes the class-sensitive features.\n",
    "    @param X: array-like, shape = [n_samples,n_inFeatures] or [n_inFeatures,], input features for input data\n",
    "    @param y: a target class (in range 0,..,num_classes-1)\n",
    "    @return array-like, shape = [n_samples,n_outFeatures], the class sensitive features for class y\n",
    "    '''\n",
    "    #The following line handles X being a 1d-array or a 2d-array\n",
    "    num_samples, num_inFeatures = (1,X.shape[0]) if len(X.shape) == 1 else (X.shape[0],X.shape[1])\n",
    "    #your code goes here, and replaces following return\n",
    "    num_outFeatures = num_classes*num_inFeatures\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        feature_map = np.zeros(num_outFeatures)\n",
    "        feature_map[int(y*num_inFeatures):int((y+1)*num_inFeatures)] = X\n",
    "        return feature_map\n",
    "    else:\n",
    "        feature_mat = np.zeros((num_samples,num_outFeatures))\n",
    "        for i, xi in enumerate(X):\n",
    "            feature_mat[i][y[i]*num_inFeatures:(y[i]+1)*num_inFeatures] = xi\n",
    "        return feature_mat\n",
    "\n",
    "def sgd(X, y, num_outFeatures, subgd, eta = 0.1, T = 10000):\n",
    "    '''\n",
    "    Runs subgradient descent, and outputs resulting parameter vector.\n",
    "    @param X: array-like, shape = [n_samples,n_features], input training data \n",
    "    @param y: array-like, shape = [n_samples,], class labels\n",
    "    @param num_outFeatures: number of class-sensitive features\n",
    "    @param subgd: function taking x,y and giving subgradient of objective\n",
    "    @param eta: learning rate for SGD\n",
    "    @param T: maximum number of iterations\n",
    "    @return: vector of weights\n",
    "    '''\n",
    "    num_samples = X.shape[0]\n",
    "    w = np.zeros(num_outFeatures)\n",
    "    #your code goes here and replaces following return statement\n",
    "    t=1\n",
    "    while(t<=T):\n",
    "        random_indx = np.random.choice(2000)\n",
    "        w -= eta * subgd(X[random_indx], y[random_indx], w)\n",
    "        t += 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Multiclass SVM\n",
    "class MulticlassSVM(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    Implements a Multiclass SVM estimator.\n",
    "    '''\n",
    "    def __init__(self, lam=1.0, num_classes=4, Delta=zeroOne, Psi=featureMap):       \n",
    "        '''\n",
    "        Creates a MulticlassSVM estimator.\n",
    "        @param num_outFeatures: number of class-sensitive features produced by Psi\n",
    "        @param lam: l2 regularization parameter\n",
    "        @param num_classes: number of classes (assumed numbered 0,..,num_classes-1)\n",
    "        @param Delta: class-sensitive loss function taking two arguments (i.e., target margin)\n",
    "        @param Psi: class-sensitive feature map taking two arguments\n",
    "        '''\n",
    "        self.lam = lam\n",
    "        self.num_classes = num_classes\n",
    "        self.Delta = Delta\n",
    "        self.Psi = lambda X,y : Psi(X,y,num_classes)\n",
    "        self.fitted = False\n",
    "    \n",
    "    def subgradient(self,x,y,w):\n",
    "        '''\n",
    "        Computes the subgradient at a given data point x,y\n",
    "        @param x: sample input\n",
    "        @param y: sample class\n",
    "        @param w: parameter vector\n",
    "        @return returns subgradient vector at given x,y,w\n",
    "        '''\n",
    "        #Your code goes here and replaces the following return statement\n",
    "        temp_list = []\n",
    "        for yi in range(self.num_classes):\n",
    "            temp_list.append(self.Delta(y,yi)-np.dot(w, self.Psi(x,y)-self.Psi(x,yi)))\n",
    "        y_hat = np.argmax(temp_list)\n",
    "        g = 2*self.lam*w + self.Psi(x,y_hat)-self.Psi(x,y)\n",
    "        return g\n",
    "    \n",
    "    def fit(self,X,y,eta=0.01,T=10000):\n",
    "        '''\n",
    "        Fits multiclass SVM\n",
    "        @param X: array-like, shape = [num_samples,num_inFeatures], input data\n",
    "        @param y: array-like, shape = [num_samples,], input classes\n",
    "        @param eta: learning rate for SGD\n",
    "        @param T: maximum number of iterations\n",
    "        @return returns self\n",
    "        '''\n",
    "        num_outFeatures = X.shape[1] * self.num_classes\n",
    "        self.coef_ = sgd(X,y,num_outFeatures,self.subgradient,eta,T)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        '''\n",
    "        Returns the score on each input for each class. Assumes\n",
    "        that fit has been called.\n",
    "        @param X : array-like, shape = [n_samples, n_inFeatures]\n",
    "        @return array-like, shape = [n_samples, n_classes] giving scores for each sample,class pairing\n",
    "        '''\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data.\")\n",
    "        num_samples = X.shape[0]\n",
    "        #Your code goes here and replaces following return statement\n",
    "        score_matrix = np.zeros((num_samples, self.num_classes))\n",
    "        for i, x_i in enumerate(X):\n",
    "            score_matrix[i,:] = [np.dot(self.coef_, self.Psi(x_i,yi)) for yi in range(self.num_classes)]\n",
    "        return score_matrix\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict the class with the highest score.\n",
    "        @param X: array-like, shape = [n_samples, n_inFeatures], input data to predict\n",
    "        @return array-like, shape = [n_samples,], class labels predicted for each data point\n",
    "        '''\n",
    "\n",
    "        #Your code goes here and replaces following return statement\n",
    "        score_matrix = self.decision_function(X)\n",
    "        predicts = np.argmax(score_matrix, axis = 1)\n",
    "        return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set confusion matrix:\n",
      "\n",
      "[[482   0 198   0   0  47 157   0  16   0]\n",
      " [ 40   0 115   0   0   5 204   0  32   0]\n",
      " [ 31   0 358   0   0   0 473   0  38   0]\n",
      " [ 32   0 121   2   0   0 730   0  15   0]\n",
      " [ 51   0 139   1   0  17 582   2 108   0]\n",
      " [424   0 231   0   0  37 193   0  22   0]\n",
      " [  2   0   2   0   0   0 338   0   0   0]\n",
      " [ 98   0 261   1   0  48 478   0  18   0]\n",
      " [120   0 146   0   0  31 211   0 338   0]\n",
      " [ 16   0 322   0   0   6 499   0  57   0]]\n"
     ]
    }
   ],
   "source": [
    "#the following code tests the MulticlassSVM and sgd\n",
    "#will fail if MulticlassSVM is not implemented yet\n",
    "train_est = MulticlassSVM(lam=1, num_classes = 10)\n",
    "train_est.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"\\nTrain set confusion matrix:\\n\")\n",
    "print(metrics.confusion_matrix(y_train, train_est.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(y_real, y_predict):\n",
    "    '''\n",
    "    Calculating accuracy rate of the model\n",
    "    y_real: 1d-array, real classes of n entry x\n",
    "    y_predict: 1d-array, predicted classes of n entry x\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    corrects = ((y_real==).sum()\n",
    "    return corrects/y_real.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuary rate of training set is:\n",
      "0.197\n"
     ]
    }
   ],
   "source": [
    "# Accuracy rate of the linear multiclass SVM\n",
    "print('The accuary rate of training set is:')\n",
    "print(cal_accuracy(y_train.reshape(-1), train_est.predict(X_train)).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kernelized multiclass SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that linear multiclass SVM performs pretty bad in this audio classification task. Next we will try kernelized multiclass SVM to build the model and see whether situation goes better-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs all kernel multiclass SVM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "\n",
    "class OneVsAllClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"\n",
    "    One-vs-all classifier\n",
    "    We assume that the classes will be the integers 0,..,(n_classes-1).\n",
    "    We assume that the estimator provided to the class, after fitting, has a \"decision_function\" that \n",
    "    returns the score for the positive class.\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, n_classes):      \n",
    "        \"\"\"\n",
    "        Constructed with the number of classes and an estimator (e.g. an\n",
    "        SVM estimator from sklearn)\n",
    "        @param estimator : binary base classifier used\n",
    "        @param n_classes : number of classes\n",
    "        \"\"\"\n",
    "        self.n_classes = n_classes \n",
    "        self.estimators = [clone(estimator) for _ in range(n_classes)]\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This should fit one classifier for each class.\n",
    "        self.estimators[i] should be fit on class i vs rest\n",
    "        @param X: array-like, shape = [n_samples,n_features], input data\n",
    "        @param y: array-like, shape = [n_samples,] class labels\n",
    "        @return returns self\n",
    "        \"\"\"\n",
    "        #Your code goes here\n",
    "        for i in range(len(self.estimators)):\n",
    "            y_list = np.zeros(len(y))\n",
    "            y_list = np.where(y==i, 1, 0)\n",
    "            self.estimators[i].fit(X,y_list)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Returns the score of each input for each class. Assumes\n",
    "        that the given estimator also implements the decision_function method (which sklearn SVMs do), \n",
    "        and that fit has been called.\n",
    "        @param X : array-like, shape = [n_samples, n_features] input data\n",
    "        @return array-like, shape = [n_samples, n_classes]\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data.\")\n",
    "\n",
    "        if not hasattr(self.estimators[0], \"decision_function\"):\n",
    "            raise AttributeError(\n",
    "                \"Base estimator doesn't have a decision_function attribute.\")\n",
    "        \n",
    "        #Replace the following return statement with your code\n",
    "        ret_row = X.shape[0]\n",
    "        ret_col = self.n_classes\n",
    "        ret_mat = np.zeros((ret_row, ret_col))\n",
    "        for i in range(self.n_classes):\n",
    "            ret_mat[:,i] = self.estimators[i].decision_function(X)\n",
    "        return ret_mat\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class with the highest score.\n",
    "        @param X: array-like, shape = [n_samples,n_features] input data\n",
    "        @returns array-like, shape = [n_samples,] the predicted classes for each input\n",
    "        \"\"\"\n",
    "        #Replace the following return statement with your code\n",
    "        all_predicts = self.decision_function(X)\n",
    "        predict = np.argmax(all_predicts, axis = 1)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel function generators\n",
    "def RBF_kernel(X1,X2,sigma):\n",
    "    \"\"\"\n",
    "    Computes the RBF kernel between two sets of vectors   \n",
    "    Args:\n",
    "        X1 - an n1xd matrix with vectors x1_1,...,x1_n1 in the rows\n",
    "        X2 - an n2xd matrix with vectors x2_1,...,x2_n2 in the rows\n",
    "        sigma - the bandwidth (i.e. standard deviation) for the RBF/Gaussian kernel\n",
    "    Returns:\n",
    "        matrix of size n1xn2, with exp(-||x1_i-x2_j||^2/(2 sigma^2)) in position i,j\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    rbf_kernel = np.zeros(shape = (X1.shape[0],X2.shape[0]))\n",
    "    norm = scipy.spatial.distance.cdist(X1,X2,'sqeuclidean')\n",
    "    rbf_kernel = np.exp(-norm/(2*sigma**2))\n",
    "    return rbf_kernel\n",
    "    \n",
    "def polynomial_kernel(X1, X2, offset, degree):\n",
    "    \"\"\"\n",
    "    Computes the inhomogeneous polynomial kernel between two sets of vectors\n",
    "    Args:\n",
    "        X1 - an n1xd matrix with vectors x1_1,...,x1_n1 in the rows\n",
    "        X2 - an n2xd matrix with vectors x2_1,...,x2_n2 in the rows\n",
    "        offset, degree - two parameters for the kernel\n",
    "    Returns:\n",
    "        matrix of size n1xn2, with (offset + <x1_i,x2_j>)^degree in position i,j\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    return (offset+linear_kernel(X1,X2))**degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for convenient prediction\n",
    "class Kernel_Machine(object):\n",
    "    def __init__(self, kernel, prototype_points, weights):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            kernel(W,X) - a function return the cross-kernel matrix between rows of W and rows of X for kernel k\n",
    "            prototype_points - an Rxd matrix with rows mu_1,...,mu_R\n",
    "            weights - a vector of length R\n",
    "        \"\"\"\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.prototype_points = prototype_points\n",
    "        self.weights = weights\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Evaluates the kernel machine on the points given by the rows of X\n",
    "        Args:\n",
    "            X - an nxd matrix with inputs x_1,...,x_n in the rows\n",
    "        Returns:\n",
    "            Vector of kernel machine evaluations on the n points in X.  Specifically, jth entry of return vector is\n",
    "                Sum_{i=1}^R w_i k(x_j, mu_i)\n",
    "        \"\"\"\n",
    "        cross_kernel_matrix = self.kernel(X, self.prototype_points)\n",
    "        return np.dot(cross_kernel_matrix,self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_soft_svm takes the numpy arrays containing the measurements of x in R^{2 x d} and y in R^d, \n",
    "the kernel, the maximum number of SGD steps T and the regularization parameter Lambda.\n",
    "It returns the corresponding Kernel_Machine.\n",
    "'''\n",
    "def train_soft_svm(X, y, kernel, T, Lambda):\n",
    "    \n",
    "    # sgd_for_soft_svm implements the above-mentioned method from SSBD.\n",
    "    # It takes the numpy arrays containing the measurements y in {-1,+1},\n",
    "    # the kernel K in R^{d x d} the maximum number of steps T and \n",
    "    # the regularization parameter lambda. It returns the coefficients alpha_bar\n",
    "    # of the solution w_bar represented as a linear combination  \n",
    "    def sgd_for_soft_svm (y, K, T, Lambda): \n",
    "        sample_size = len(y)\n",
    "        beta=[] \n",
    "        beta.append(np.zeros(sample_size))\n",
    "        alpha = []\n",
    "    \n",
    "        for t in range(T):\n",
    "            alpha_temp= (beta[t] / (Lambda*(t+1) ))\n",
    "            i = np.random.randint(sample_size)\n",
    "            beta_temp = beta[t]\n",
    "            temp=0\n",
    "            for j in range (sample_size): \n",
    "                temp = temp+ alpha_temp[j]* K[j,i]\n",
    "            if ((y[i]*temp)<1):\n",
    "                beta_temp[i]= beta_temp[i]+y[i]         \n",
    "            beta.append(beta_temp)\n",
    "            alpha.append(alpha_temp)\n",
    "        alpha_bar = 1/T* np.sum(alpha, axis=0)                  \n",
    "        return alpha_bar\n",
    "    \n",
    "    K = kernel(X,X)\n",
    "    alpha= sgd_for_soft_svm (y, K, T, Lambda)\n",
    "    return Kernel_Machine(kernel, X, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\n",
    "\n",
    "# Kernel soft SVM class\n",
    "class KernelSoftSVM(BaseEstimator, RegressorMixin):  \n",
    "    \"\"\"sklearn wrapper for our kernel ridge regression\"\"\"\n",
    "     \n",
    "    def __init__(self, kernel=\"linear\", sigma=1, degree=2, offset=1, T = 1000, l2reg=0.2):        \n",
    "        self.kernel = kernel\n",
    "        self.sigma = sigma\n",
    "        self.degree = degree\n",
    "        self.offset = offset\n",
    "        self.l2reg = l2reg \n",
    "        self.T = T\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This should fit classifier. All the \"work\" should be done here.\n",
    "        \"\"\"\n",
    "        if (self.kernel == \"linear\"):\n",
    "            self.k = linear_kernel\n",
    "        elif (self.kernel == \"RBF\"):\n",
    "            self.k = functools.partial(RBF_kernel, sigma=self.sigma)\n",
    "        elif (self.kernel == \"polynomial\"):\n",
    "            self.k = functools.partial(polynomial_kernel, offset=self.offset, degree=self.degree)\n",
    "        else:\n",
    "            raise ValueError('Unrecognized kernel type requested.')\n",
    "        \n",
    "        self.kernel_machine_ = train_soft_svm(X, y, self.k, self.T, self.l2reg)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"kernel_machine_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return(self.kernel_machine_.predict(X))\n",
    "        \n",
    "    def score(self, X, y=None):\n",
    "        # get the average square error\n",
    "        return((self.predict(X)-y).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Try the kernel multiclass support vector classfier provided by *sklearn* module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsAllClassifier(estimator=None, n_classes=10)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_estimator = svm.SVC(kernel = 'rbf', C=10)\n",
    "clf_onevsall = OneVsAllClassifier(svm_estimator, n_classes=10)\n",
    "clf_onevsall.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sklearn SVM: Train set confusion matrix:\n",
      "\n",
      "[[900   0   0   0   0   0   0   0   0   0]\n",
      " [  0 396   0   0   0   0   0   0   0   0]\n",
      " [  0   0 900   0   0   0   0   0   0   0]\n",
      " [  0   3   0 897   0   0   0   0   0   0]\n",
      " [  0   0   0   0 900   0   0   0   0   0]\n",
      " [  0   0   0   0   0 907   0   0   0   0]\n",
      " [  0   2   0   0   0   0 340   0   0   0]\n",
      " [  0   0   0   0   0   0   0 904   0   0]\n",
      " [  0   0   0   0   0   0   0   0 846   0]\n",
      " [  0   0   0   0   0   0   0   0   0 900]]\n"
     ]
    }
   ],
   "source": [
    "svm_estimator.fit(X_train,y_train)\n",
    "y_train_predict = svm_estimator.predict(X_train)\n",
    "print(\"\\nsklearn SVM: Train set confusion matrix:\\n\")\n",
    "print(metrics.confusion_matrix(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of the sklearn multiclass SVM in traing set:\n",
      "0.999\n"
     ]
    }
   ],
   "source": [
    "# Accuracy rate of sklearn multiclass SVM in traing set\n",
    "print('Accuracy rate of the sklearn multiclass SVM in traing set:')\n",
    "print(cal_accuracy(y_train.reshape(-1), y_train_predict).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sklearn SVM: Validation set confusion matrix:\n",
      "\n",
      "[[ 29   0  71   0   0   0   0   0   0   0]\n",
      " [  0   0  33   0   0   0   0   0   0   0]\n",
      " [  0   0 100   0   0   0   0   0   0   0]\n",
      " [  0   0 100   0   0   0   0   0   0   0]\n",
      " [  0   0 100   0   0   0   0   0   0   0]\n",
      " [  0   0  93   0   0   0   0   0   0   0]\n",
      " [  0   0  32   0   0   0   0   0   0   0]\n",
      " [  0   0  96   0   0   0   0   0   0   0]\n",
      " [  0   0  83   0   0   0   0   0   0   0]\n",
      " [  0   0 100   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = svm_estimator.predict(X_test)\n",
    "print(\"\\nsklearn SVM: Validation set confusion matrix:\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of the sklearn multiclass SVM in traing set:\n",
      "0.154\n"
     ]
    }
   ],
   "source": [
    "# Accuracy rate of sklearn multiclass SVM in traing set\n",
    "print('Accuracy rate of the sklearn multiclass SVM in traing set:')\n",
    "print(cal_accuracy(y_test.reshape(-1), y_test_predict).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that sklearn SVM performs pretty good in training set with a nearly 100% percent accuracy. However, the performance on the validation set becomes pretty bad. It causes obvious overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Try the kernelized multiclass SVM writen by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsAllClassifier(estimator=None, n_classes=10)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_estimator = KernelSoftSVM(kernel = 'RBF',sigma=1, T = 2000, l2reg=1)\n",
    "clf_onevsall = OneVsAllClassifier(svm_estimator, n_classes=10)\n",
    "clf_onevsall.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set confusion matrix:\n",
      "\n",
      "[[900   0   0   0   0   0   0   0   0   0]\n",
      " [281 115   0   0   0   0   0   0   0   0]\n",
      " [693   0 207   0   0   0   0   0   0   0]\n",
      " [700   3   0 197   0   0   0   0   0   0]\n",
      " [679   0   0   0 219   0   0   2   0   0]\n",
      " [443   0   0   0   0 464   0   0   0   0]\n",
      " [261   2   0   0   0   0  79   0   0   0]\n",
      " [662   0   0   0   5   0   0 236   0   1]\n",
      " [648   0   0   0   0   0   0   0 198   0]\n",
      " [707   0   0   0   0   0   0   0   0 193]]\n"
     ]
    }
   ],
   "source": [
    "y_train_predict2 = clf_onevsall.predict(X_train)\n",
    "print(\"\\nTrain set confusion matrix:\\n\")\n",
    "print(metrics.confusion_matrix(y_train, y_train_predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of the my kernel multiclass SVM in traing set:\n",
      "0.356\n"
     ]
    }
   ],
   "source": [
    "# Accuracy rate of sklearn multiclass SVM in traing set\n",
    "print('Accuracy rate of the my kernel multiclass SVM in traing set:')\n",
    "print(cal_accuracy(y_train.reshape(-1), y_train_preidict2).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Parameter adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the long running time for each adjustment, I only tried very limited range of parameter adjustment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate in training set(sigma = 0.1):\n",
      "0.312\n",
      "Accuracy rate in validation set(sigma = 0.1):\n",
      "0.119\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(sigma = 1):\n",
      "0.362\n",
      "Accuracy rate in validation set(sigma = 1):\n",
      "0.119\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(sigma = 10):\n",
      "0.645\n",
      "Accuracy rate in validation set(sigma = 10):\n",
      "0.281\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(sigma = 100):\n",
      "0.608\n",
      "Accuracy rate in validation set(sigma = 100):\n",
      "0.4\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(sigma = 1000):\n",
      "0.249\n",
      "Accuracy rate in validation set(sigma = 1000):\n",
      "0.27\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Find the best sigma\n",
    "y_train_predict_list = []\n",
    "y_test_predict_list = []\n",
    "for sigma in range(-1,4):\n",
    "    svm_estimatori = KernelSoftSVM(kernel = 'RBF',sigma=10**sigma, T = 2000, l2reg=1)\n",
    "    clf_onevsalli = OneVsAllClassifier(svm_estimatori, n_classes=10)\n",
    "    clf_onevsalli.fit(X_train,y_train)\n",
    "    y_train_predicti = clf_onevsalli.predict(X_train)\n",
    "    y_test_predicti = clf_onevsalli.predict(X_test)\n",
    "    y_train_predict_list.append(y_train_predicti)\n",
    "    y_test_predict_list.append(y_test_predicti)\n",
    "    print('Accuracy rate in training set(sigma = {}):'.format(10**sigma))\n",
    "    print(cal_accuracy(y_train.reshape(-1), y_train_predicti).round(3))\n",
    "    print('Accuracy rate in validation set(sigma = {}):'.format(10**sigma))\n",
    "    print(cal_accuracy(y_test.reshape(-1), y_test_predicti).round(3))\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate in training set(l2reg = 0.5):\n",
      "0.589\n",
      "Accuracy rate in validation set(l2reg = 0.5):\n",
      "0.436\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(l2reg = 1):\n",
      "0.605\n",
      "Accuracy rate in validation set(l2reg = 1):\n",
      "0.41\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(l2reg = 5):\n",
      "0.616\n",
      "Accuracy rate in validation set(l2reg = 5):\n",
      "0.399\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(l2reg = 10):\n",
      "0.607\n",
      "Accuracy rate in validation set(l2reg = 10):\n",
      "0.461\n",
      "--------------------------------------------------\n",
      "Accuracy rate in training set(l2reg = 20):\n",
      "0.603\n",
      "Accuracy rate in validation set(l2reg = 20):\n",
      "0.416\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Find the best l2reg\n",
    "y_train_predict_list_l = []\n",
    "y_test_predict_list_l = []\n",
    "for l2reg in [0.5,1,5,10,20]:\n",
    "    svm_estimatorj = KernelSoftSVM(kernel = 'RBF',sigma=100, T = 2000, l2reg=l2reg)\n",
    "    clf_onevsallj = OneVsAllClassifier(svm_estimatorj, n_classes=10)\n",
    "    clf_onevsallj.fit(X_train,y_train)\n",
    "    y_train_predictj = clf_onevsallj.predict(X_train)\n",
    "    y_test_predictj = clf_onevsallj.predict(X_test)\n",
    "    y_train_predict_list_l.append(y_train_predictj)\n",
    "    y_test_predict_list_l.append(y_test_predictj)\n",
    "    print('Accuracy rate in training set(l2reg = {}):'.format(l2reg))\n",
    "    print(cal_accuracy(y_train.reshape(-1), y_train_predictj).round(3))\n",
    "    print('Accuracy rate in validation set(l2reg = {}):'.format(l2reg))\n",
    "    print(cal_accuracy(y_test.reshape(-1), y_test_predictj).round(3))\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will choose the set of parameters with the highest accuarcy rate in test set.\n",
    "\n",
    "Because both the single kernel SVM and the multiclass kernel SVM use Stochastic Gradient Decent (SGD), the number of iteration do relate to the final result. Finally let's try whether increasing the number of iteration would help with getting a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate in training set(More iteration):\n",
      "0.681\n",
      "Accuracy rate in validation set(More iteration):\n",
      "0.467\n"
     ]
    }
   ],
   "source": [
    "svm_estimatork = KernelSoftSVM(kernel = 'RBF',sigma=100, T = 5000, l2reg=10)\n",
    "clf_onevsallk = OneVsAllClassifier(svm_estimatork, n_classes=10)\n",
    "clf_onevsallk.fit(X_train,y_train)\n",
    "y_train_predictk = clf_onevsallk.predict(X_train)\n",
    "y_test_predictk = clf_onevsallk.predict(X_test)\n",
    "print('Accuracy rate in training set(More iteration):')\n",
    "print(cal_accuracy(y_train.reshape(-1), y_train_predictk).round(3))\n",
    "print('Accuracy rate in validation set(More iteration):')\n",
    "print(cal_accuracy(y_test.reshape(-1), y_test_predictk).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both accuarcte rates of train and validation set are improved to some extent. Because our main goal is to find the possible way to build the urban sound classification model, our parameter tuning ends here though there is still a large space for us to adjust. We regard 'sigma = 100' and 'l2reg = 10' as our final parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Present final outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will present the final outcome in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set confusion matrix:\n",
      "\n",
      "[[602   2   6   2   5 174   0  65   2  42]\n",
      " [ 26  95  14   7  28  40  10 106   2  68]\n",
      " [ 24   2 554  32  18  48   5  27  12 178]\n",
      " [ 24   3  77 624  20  35  35  10   7  65]\n",
      " [ 52   5   4  10 506  32  15 236   1  39]\n",
      " [ 83   2   2   2   3 656   2 106   1  50]\n",
      " [  1   0   4  18  21   2 287   3   0   6]\n",
      " [ 56   2   2   2  25  17   2 781   0  17]\n",
      " [ 29   2  29  10   2  79   2  42 581  70]\n",
      " [ 12   1  54   4  12  39   2  75  12 689]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for training set\n",
    "print(\"\\nTraining set confusion matrix:\\n\")\n",
    "print(metrics.confusion_matrix(y_train, y_train_predictk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accurate rate for each class\n",
    "def accuracy_for_classes(confusion_matrix):\n",
    "    confusion_matrix = np.array(confusion_matrix)\n",
    "    num_each_class = np.sum(confusion_matrix, axis = 1)\n",
    "    correct_each_class = np.zeros(confusion_matrix.shape[0])\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        correct_each_class[i] = confusion_matrix[i,i]\n",
    "    accuracy_each_class = correct_each_class/num_each_class\n",
    "    return accuracy_each_class       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# present accuarte rate of different sound classes in training set\n",
    "accuracy_each_class1 = accuracy_for_classes(metrics.confusion_matrix(y_train, y_train_predictk))\n",
    "accuracy_each_class2 = accuracy_for_classes(metrics.confusion_matrix(y_test, y_test_predictk))\n",
    "classes = ['air conditioner', 'car horn', 'children playing', 'dog bark', 'drilling',\n",
    "         'enginge idling', 'gun shot', 'jackhammer', 'siren', 'street_music']\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.bar(range(10), accuracy_each_class1, width=1/4, tick_label = classes, label = \"train\")\n",
    "plt.bar(np.arange(10)+1/4, accuracy_each_class2, width=1/4, label = \"test\")\n",
    "plt.xticks(np.arange(10)+1/8,rotation=-15)\n",
    "plt.title(\"Accuarte Rate of Different Sound Classes in Training Set\")\n",
    "plt.xlabel(\"Class of Urban Sound\")\n",
    "plt.ylabel(\"Accuarte Rate\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, we can find that sounds which is short and sharp like dog bark and gun shot are relatively easier to discriminate, compared with more gentle and persistent sounds.\n",
    "\n",
    "The final outcome shows that there is a clear gap between the accuarcy of train set and test set. It is possible to train the model to fit train set perfectly, accualy I have done it by sklearn SVM. But it would cause extreme overfitting and is unacceptable. Together with the reason that I want to test my understanding on the theories and algorithoms, I write the kernelized multiclass SVM from scratch. \n",
    "\n",
    "Due to my limited computer performance, I just do little parameter adjustment. In the future, if possible, we can use **SearchGrid** function to help with seeking the best parameter combinations. Also, as suggested by the data source, we should do the same training ten times, while in each time we set a different folder of data as validation set. Then we calculate the average accuracy to evaluate our model. Definately, there are still many works that could be done with this project. Will update this notebook in the future!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
