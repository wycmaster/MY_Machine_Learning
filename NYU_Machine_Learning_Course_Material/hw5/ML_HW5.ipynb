{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML HW5\n",
    "## Zhiqi Guo(zg475)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Hinge loss is a convex surrogate for 0/1 loss\n",
    "1.Show that $1(y \\neq sign(f (x)) ≤ max \\{0,1-yf(x) \\} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $y \\neq sign(f(x))$   \n",
    "* if f(x) > 0 $\\Rightarrow sign(f(x)) = 1$, then $y = -1$   \n",
    "$max\\{0,1-(-1)f(x)\\} > 1$   Thus, $ 1 < max \\{0,1-yf(x) \\}$   \n",
    "\n",
    "\n",
    "* if f(x) < 0 $\\Rightarrow sign(f(x)) = -1$, then $y =1$   \n",
    "$max \\{0, 1-1 \\cdot f(x) \\} > 1$  Thus, $ 1 < max \\{0,1-yf(x) \\}$   \n",
    "\n",
    "\n",
    "* if f(x) = 0 $\\Rightarrow sign(f(x)) = 0 $, then   \n",
    "$max \\{0, 1-1 \\cdot 0 \\} = 1 $ \n",
    "\n",
    "Thus, $1(y \\neq sign(f (x)) ≤ max \\{0,1-yf(x) \\} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Show that the hinge loss max {0, 1 − m} is a convex function of the margin m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 0 is a constant function and 1-m is an affine function. Then according to the convex-optimization lecture notes, that Maximum of convex functions is convex, we could  their pointwise maximum is convex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Suppose our prediction score functions are given by $f_w(x) = w^T x$. The hinge loss of $f_w$ on any example (x, y) is then $max \\{ 0, 1 − yw^T x \\}$ . Show that this is a convex function of w. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to convex-optimization lecture notes that f is an affine function (or affine mapping) if it is a sum of a linear function and a constant. Thus, $1-yw^Tx$ is an affine function. Thus by the same argument as in part 2, we conclude $max \\{ 0, 1 − yw^T x \\}$ is convex function of w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generalized Hinge Loss\n",
    "1.Justify that for any x∈X and y∈Y,we have $h(x, y) ≤ h(x, f (x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the definition of f(x) that $f(x) = arg max_{y \\in Y} h(x,y)$   \n",
    "Thus $h(x,y) \\leq h(x,f(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Justify the following two inequalities:   \n",
    "$∆(y,f(x)) ≤ ∆(y,f(x))+h(x,f(x))−h(x,y) ≤ max_{y′∈Y}[∆(y,y′))+h(x,y′)−h(x,y)]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $h(x,y) \\leq h(x,f(x))$, thus $h(x,f(x))−h(x,y) \\geq 0$, we automatically have $∆(y,f(x)) ≤ ∆(y,f(x))+h(x,f(x))−h(x,y)$   \n",
    "Also, since $f(x) \\in \\mathbb{A}$, we automatically have $∆(y,f(x))+h(x,f(x))−h(x,y) ≤ max_{y′∈Y}[∆(y,y′))+h(x,y′)−h(x,y)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Show that we can write the generalized hinge loss for hw(x,y) on example (xi,yi) as $l (h_w, (x_i, y_i)) = max_{y \\in Y} [∆ (yi, y)) + ⟨w, Ψ(xi, y) − Ψ(xi, yi)⟩] .$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could directly induce this by the definition of generalized hinge loss hypothesis space: \n",
    "\n",
    "$L(h_w,(x_i,y_i)) = max_{y \\in Y} ∆(y_i,y)+h_w(x_i,y)-h_w(x_i,y_i) = max_{y \\in Y} [∆(y_i,y) + <w,\\phi(x_i,y)> - <w,\\phi(x_i,y_i)>] = max_{y \\in Y} [∆(y_i,y) + <w, \\phi(x_i,y)-\\phi(x_i,y_i)>]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.(a) The expression $∆(yi, y) + ⟨w, Ψ(xi, y) − Ψ(xi, yi)⟩$ is an affine function of w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the respect to w, $∆(yi, y)$ is a constant scalar and $Ψ(xi, y) − Ψ(xi, yi)$ is a constant vector. Thus  $∆(yi, y) + ⟨w, Ψ(xi, y) − Ψ(xi, yi)⟩$ is a sum of a linear function and a constant, thus it's an affien function of w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.(b) The expression $max_{y∈Y} [∆ (yi, y)) + ⟨w, Ψ(xi, y) − Ψ(xi, yi)⟩] $ is a convex function of w.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each $y \\in Y$, we have an affine function inside, which is a convex function. And by the convex-optimization notes, Maximum of convex functions is convex. Thus, $max_{y∈Y} [∆ (yi, y)) + ⟨w, Ψ(xi, y) − Ψ(xi, yi)⟩] $ is a convex function of w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Conclude that $l(h_w,(xi,yi))$ is a convex surrogate for $∆(yi,f_w(xi))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, A convex surrogate loss function is a convex function that is an upper bound for the loss function of interest. We have shown that for any x ∈ X,y ∈ Y,h ∈ H we have $l(h_w,(x_i,y_i)) ≥ ∆(y_i,f_w(x_i))$, which gives an upper bound, also $l(h_w,(x_i,y_i)) $ is a convex function. THus it's a convex surrogate for $∆(yi,f_w(xi))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.SGD for Multiclass SVM\n",
    "1.(a) $\\frac{1}{n}\\sum_{i=1}^{n} max_{y∈Y} [∆ (y_i, y) + ⟨w, Ψ(x_i, y) − Ψ(x_i, y_i)⟩] $ is a convex function of w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown in the previous problem that $w → max_{y∈Y} [∆ (y_i, y) + ⟨w, Ψ(x_i, y) − Ψ(x_i, y_i)⟩]$ is a convex function of w, and since nonnegative weighted sums of convex functions is convex. Thus $\\frac{1}{n}\\sum_{i=1}^{n} max_{y∈Y} [∆ (y_i, y) + ⟨w, Ψ(x_i, y) − Ψ(x_i, y_i)⟩] $ is also a convex function of w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.(b)  $∥w∥_2$ is a convex function of w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since every norm on $R^n$ is convex, thus $∥w∥_2$ is a convex function of w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.(c) J(w) is a convex function of w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By part (a) and (b), J(w) is the sum of two non-negative convex functions, thus J(w) is a convex function of w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Give an expression for a subgradient of J(w). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define $\\hat{y} = arg max_{y∈Y} [∆ (y_i, y) + ⟨w, Ψ(x_i, y) − Ψ(x_i, y_i)⟩]$\n",
    "\n",
    "subgradient $g = 2 \\lambda w + \\frac{1}{n}\\sum_{i=1}^{n} [Ψ(x_i, \\hat{y}) − Ψ(x_i, y_i)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Give an expression the stochastic subgradient based on the point (xi,yi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stochastic subgradient $g = 2\\lambda w + [Ψ(x_i, \\hat{y}) − Ψ(x_i, y_i)] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Give an expression for a mini batch subgradient,based on the points $(xi,yi),...,(x_{i+m−1},y_{i+m−1}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mini batch subgradient $g = 2\\lambda w +  \\frac{1}{m}\\sum_{j=i}^{i+m-1} [Ψ(x_j, \\hat{y}) − Ψ(x_j, y_j)]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.[OPTIONAL] Another Formulation of Generalized Hinge Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Show that $l (h, (x_i, y_i)) = max_{y′∈Y} [∆ (y_i, y′) − m_{i,y′} (h)]. $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "l (h, (x_i, y_i)) &=  max_{y′∈Y} [∆ (y_i, y′)+h(x_i,y')-h(x_i, y_i)]\\\\\n",
    "                  &=  max_{y′∈Y} [∆ (y_i, y′)-(h(x_i, y_i)-h(x_i,y'))]\\\\\n",
    "                  &=  max_{y′∈Y} [∆ (y_i, y′)-m_{i,y′} (h)]\n",
    "\\end{split}\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Show that for any example (xi, yi) and any score function h, the multiclass hinge loss we gave in lecture and the generalized hinge loss presented above are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown in the previous problem that $l(h_w,(x_i,y_i)) \\geq ∆(y,f(x)) \\geq 0 $   \n",
    "Since $l(h_w,(x_i,y_i)) = max_{y′∈Y} [∆ (y_i, y′)-m_{i,y′} (h)]$ is always greater or equal to 0   \n",
    "We have $max_{y∈Y} [∆ (y_i, y)-m_{i,y} (h)]_{+} = max_{y∈Y} [∆ (y_i, y)-m_{i,y} (h)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Show that l(h,(xi,yi)) = 0 if we assume that ∆(y,y) = 0 for all y ∈ Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "l (h, (x_i, y_i)) &=  max_{y′∈Y} [∆ (y_i, y′)+h(x_i,y')-h(x_i, y_i)]\\\\\n",
    "                  &=  max_{y′∈Y} [∆_{y'=y_i} (y_i, y′), max_{y'\\neq y_i}[∆ (y_i, y′)-(h(x_i, y_i)-h(x_i,y'))]]\\\\\n",
    "                  &=  max_{y′∈Y} [0, max_{y'\\neq y_i}[∆ (y_i, y′)-m_{i,y′} (h)]] \\\\\n",
    "                  &=  max_{y′∈Y} [0, \\leq 0] \\\\\n",
    "                  &= 0\n",
    "\\end{split}\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. [OPTIONAL]Hinge Loss is a Special Case of Generalized Hinge Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "l (h, (x, y)) &=  max_{y′∈Y} [∆ (y, y′)+h(x,y')-h(x, y)]\\\\\n",
    "                  &=  max [∆_{y'=y} (y, y), max_{y'\\neq y}[∆ (y, y′)-(h(x, y')-h(x,y))]]\\\\\n",
    "                  &=  max [0, 1+ [-g(x)/2-g(x)/2]]  \\quad (if\\ y=1, y' = -1)\\\\ \n",
    "                  &=  max [0, 1- yg(x)] \\\\\n",
    "                  &\n",
    "\\end{split}\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "l (h, (x, y)) &=  max_{y′∈Y} [∆ (y, y′)+h(x,y')-h(x, y)]\\\\\n",
    "                  &=  max [∆_{y'=y} (y, y), max_{y'\\neq y}[∆ (y, y′)-(h(x, y')-h(x,y))]]\\\\\n",
    "                  &=  max [0, 1+ [g(x)/2+g(x)/2]]  \\quad (if\\ y= -1, y' = 1)\\\\ \n",
    "                  &=  max [0, 1 + g(x)] \\\\\n",
    "                  &=  max [0, 1 - yg(x)] \n",
    "\\end{split}\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6.1 One-vs-All (also known as One-vs-Rest)\n",
    "1.Complete the class OneVsAllClassifier in the skeleton code. Following the OneVsAllClassifier code is a cell that extracts the results of the fit and plots the decision region. Include these results in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x5e571ca6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnXMug7y4O+dcBnlxd865DPofqFNp/P5s+gsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5e55a03e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the  training data\n",
    "np.random.seed(2)\n",
    "X, y = make_blobs(n_samples=300,cluster_std=.25, centers=np.array([(-3,1),(0,2),(3,1)]))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "\n",
    "class OneVsAllClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"\n",
    "    One-vs-all classifier\n",
    "    We assume that the classes will be the integers 0,..,(n_classes-1).\n",
    "    We assume that the estimator provided to the class, after fitting, has a \"decision_function\" that \n",
    "    returns the score for the positive class.\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, n_classes):      \n",
    "        \"\"\"\n",
    "        Constructed with the number of classes and an estimator (e.g. an\n",
    "        SVM estimator from sklearn)\n",
    "        @param estimator : binary base classifier used\n",
    "        @param n_classes : number of classes\n",
    "        \"\"\"\n",
    "        self.n_classes = n_classes \n",
    "        self.estimators = [clone(estimator) for _ in range(n_classes)]\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This should fit one classifier for each class.\n",
    "        self.estimators[i] should be fit on class i vs rest\n",
    "        @param X: array-like, shape = [n_samples,n_features], input data\n",
    "        @param y: array-like, shape = [n_samples,] class labels\n",
    "        @return returns self\n",
    "        \"\"\"\n",
    "        #Your code goes here\n",
    "        for i in range(self.n_classes):\n",
    "            y1 = (y==i)*1\n",
    "            self.estimators[i].fit(X,y1) \n",
    "        \n",
    "        self.fitted = True  \n",
    "        return self   \n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Returns the score of each input for each class. Assumes\n",
    "        that the given estimator also implements the decision_function method (which sklearn SVMs do), \n",
    "        and that fit has been called.\n",
    "        @param X : array-like, shape = [n_samples, n_features] input data\n",
    "        @return array-like, shape = [n_samples, n_classes]\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data.\")\n",
    "\n",
    "        if not hasattr(self.estimators[0], \"decision_function\"):\n",
    "            raise AttributeError(\n",
    "                \"Base estimator doesn't have a decision_function attribute.\")\n",
    "        \n",
    "        #Replace the following return statement with your code\n",
    "        temp_lst = []\n",
    "        for i in range(self.n_classes):\n",
    "            temp_lst.append(self.estimators[i].decision_function(X))\n",
    "            \n",
    "        return np.column_stack((temp_lst[0],temp_lst[1],temp_lst[2])) \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class with the highest score.\n",
    "        @param X: array-like, shape = [n_samples,n_features] input data\n",
    "        @returns array-like, shape = [n_samples,] the predicted classes for each input\n",
    "        \"\"\"\n",
    "        #Replace the following return statement with your code\n",
    "        return self.decision_function(X).argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeffs 0\n",
      "[[-1.05854193 -0.90296009]]\n",
      "Coeffs 1\n",
      "[[ 0.29542345  0.50894293]]\n",
      "Coeffs 2\n",
      "[[ 0.89050156 -0.82570517]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100,   0,   0],\n",
       "       [  0, 100,   0],\n",
       "       [  0,   9,  91]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkZRRsIuIpMz/B/shRDm+U6UTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5e55be4710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Here we test the OneVsAllClassifier\n",
    "from sklearn import svm\n",
    "svm_estimator = svm.LinearSVC(loss='hinge', fit_intercept=False, C=200)\n",
    "clf_onevsall = OneVsAllClassifier(svm_estimator, n_classes=3)\n",
    "clf_onevsall.fit(X,y)\n",
    "\n",
    "for i in range(3) :\n",
    "    print(\"Coeffs %d\"%i)\n",
    "    print(clf_onevsall.estimators[i].coef_) #Will fail if you haven't implemented fit yet\n",
    "\n",
    "# create a mesh to plot in\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = min(X[:,0])-3,max(X[:,0])+3\n",
    "y_min, y_max = min(X[:,1])-3,max(X[:,1])+3\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "mesh_input = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "Z = clf_onevsall.predict(mesh_input)\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y, clf_onevsall.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.[Optional] You may notice that every time you run the cell that fits the models and plots the decision regions, you get slightly different results. This is more pronounced when C is larger, e.g. C = 200. Investigate and propose an explanation for this. You may use any means necessary, including google searching and asking other people (just like in real life). [It’s generally good to investigate things that look odd – you’ll almost always learn something, and sometimes you’ll uncover a more serious underlying problem.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Intuitively, the C parameter tells the SVM optimization how much we want to avoid misclassifying each training example. For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Thus, a larger C probably gives us a better result in binary classification case. However, a smaller-margin which gives a higher performance in binary case may not the 'best' one in multiclass svm, or not that stable. Since we will train one classifer a time and train a svm classifier for each class. When the margin is smaller, it may not be the best case in a multiclass problem(while though it might be better in binary case). Thus, the decision boundary is more likely to slightly change when C is larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Multiclass SVM\n",
    "1.Complete the skeleton code for multiclass SVM. Following the multiclass SVM implementa- tion, we have included another block of test code. Make sure to include the results from these tests in your assignment, along with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zeroOne(y,a) :\n",
    "    '''\n",
    "    Computes the zero-one loss.\n",
    "    @param y: output class\n",
    "    @param a: predicted class\n",
    "    @return 1 if different, 0 if same\n",
    "    '''\n",
    "    return int(y != a)\n",
    "\n",
    "def featureMap(X,y,num_classes) :\n",
    "    '''\n",
    "    Computes the class-sensitive features.\n",
    "    @param X: array-like, shape = [n_samples,n_inFeatures] or [n_inFeatures,], input features for input data\n",
    "    @param y: a target class (in range 0,..,num_classes-1)\n",
    "    @return array-like, shape = [n_samples,n_outFeatures], the class sensitive features for class y\n",
    "    '''\n",
    "    #The following line handles X being a 1d-array or a 2d-array\n",
    "    num_samples, num_inFeatures = (1,X.shape[0]) if len(X.shape) == 1 else (X.shape[0],X.shape[1])\n",
    "    #your code goes here, and replaces following return\n",
    "    n_outFeatures = num_inFeatures*num_classes\n",
    "    featureMatrix = np.zeros((num_samples,n_outFeatures))\n",
    "    \n",
    "    if num_samples==1:\n",
    "        feature_map = np.zeros((n_outFeatures))\n",
    "        feature_map[y*2:y*2+2] = X\n",
    "        #feature_map[y*2+1] = X[1]\n",
    "    return feature_map\n",
    "                       \n",
    "    for index,sample in enumerate(X):\n",
    "        feature_vector = np.zeros(n_outFeatures)\n",
    "        feature_vector[y[index]*2] = sample[0]\n",
    "        feature_vector[y[index]*2+1]=sample[1]\n",
    "        featureMatrix[index] = feature_vector\n",
    "    return featureMatrix\n",
    "\n",
    "def sgd(X, y, num_outFeatures, subgd, eta = 0.1, T = 10000):\n",
    "    '''\n",
    "    Runs subgradient descent, and outputs resulting parameter vector.\n",
    "    @param X: array-like, shape = [n_samples,n_features], input training data \n",
    "    @param y: array-like, shape = [n_samples,], class labels\n",
    "    @param num_outFeatures: number of class-sensitive features\n",
    "    @param subgd: function taking x,y and giving subgradient of objective\n",
    "    @param eta: learning rate for SGD\n",
    "    @param T: maximum number of iterations\n",
    "    @return: vector of weights\n",
    "    '''\n",
    "    num_samples = X.shape[0]\n",
    "    w = np.zeros(num_outFeatures)\n",
    "    #your code goes here and replaces following return statement\n",
    "    for iteration in range(T):\n",
    "        random_indx = np.random.choice(300, 1)\n",
    "        x_i = X[random_indx]\n",
    "        y_i = y[random_indx]\n",
    "        w = w - eta * subgd(x_i,y_i,w)\n",
    "\n",
    "    return w\n",
    "\n",
    "class MulticlassSVM(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    Implements a Multiclass SVM estimator.\n",
    "    '''\n",
    "    def __init__(self, num_outFeatures, lam=1.0, num_classes=3, Delta=zeroOne, Psi=featureMap):       \n",
    "        '''\n",
    "        Creates a MulticlassSVM estimator.\n",
    "        @param num_outFeatures: number of class-sensitive features produced by Psi\n",
    "        @param lam: l2 regularization parameter\n",
    "        @param num_classes: number of classes (assumed numbered 0,..,num_classes-1)\n",
    "        @param Delta: class-sensitive loss function taking two arguments (i.e., target margin)\n",
    "        @param Psi: class-sensitive feature map taking two arguments\n",
    "        '''\n",
    "        self.num_outFeatures = num_outFeatures\n",
    "        self.lam = lam\n",
    "        self.num_classes = num_classes\n",
    "        self.Delta = Delta\n",
    "        self.Psi = lambda X,y : Psi(X,y,num_classes)\n",
    "        self.fitted = False\n",
    "    \n",
    "    def subgradient(self,x,y,w):\n",
    "        '''\n",
    "        Computes the subgradient at a given data point x,y\n",
    "        @param x: sample input\n",
    "        @param y: sample class\n",
    "        @param w: parameter vector\n",
    "        @return returns subgradient vector at given x,y,w\n",
    "        '''\n",
    "        #Your code goes here and replaces the following return statement\n",
    "        temp_lst = []\n",
    "        yi = y\n",
    "        for y_class in range(self.num_classes):\n",
    "            temp_lst.append(self.Delta(yi,y_class)+ np.dot(w, self.Psi(x,y_class)-self.Psi(x,yi)))\n",
    "        y_hat = np.argmax(temp_lst)\n",
    "        \n",
    "        g = 2*self.lam*w + (self.Psi(x,y_hat)-self.Psi(x,yi))\n",
    "        return g\n",
    "              \n",
    "    def fit(self,X,y,eta=0.01,T=10000):\n",
    "        '''\n",
    "        Fits multiclass SVM\n",
    "        @param X: array-like, shape = [num_samples,num_inFeatures], input data\n",
    "        @param y: array-like, shape = [num_samples,], input classes\n",
    "        @param eta: learning rate for SGD\n",
    "        @param T: maximum number of iterations\n",
    "        @return returns self\n",
    "        '''\n",
    "        self.coef_ = sgd(X,y,self.num_outFeatures,self.subgradient,eta,T)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        '''\n",
    "        Returns the score on each input for each class. Assumes\n",
    "        that fit has been called.\n",
    "        @param X : array-like, shape = [n_samples, n_inFeatures]\n",
    "        @return array-like, shape = [n_samples, n_classes] giving scores for each sample,class pairing\n",
    "        '''\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data.\")\n",
    "        num_samples = X.shape[0]\n",
    "        #Your code goes here and replaces following return statement\n",
    "        score_matrix = np.zeros((num_samples,self.num_classes))\n",
    "        for index, sample in enumerate(X):\n",
    "            xi=sample\n",
    "            score_matrix[index,:] = [np.dot(self.coef_, self.Psi(xi,yi)) for yi in range(self.num_classes) ]\n",
    "        \n",
    "        return score_matrix\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict the class with the highest score.\n",
    "        @param X: array-like, shape = [n_samples, n_inFeatures], input data to predict\n",
    "        @return array-like, shape = [n_samples,], class labels predicted for each data point\n",
    "        '''\n",
    "\n",
    "        #Your code goes here and replaces following return statement\n",
    "        return self.decision_function(X).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-75264df5a810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m#will fail if MulticlassSVM is not implemented yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMulticlassSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"w:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3e81ec34c36e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, eta, T)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[1;32mreturn\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         '''\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_outFeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubgradient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3e81ec34c36e>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(X, y, num_outFeatures, subgd, eta, T)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mx_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_indx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0my_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_indx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msubgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3e81ec34c36e>\u001b[0m in \u001b[0;36msubgradient\u001b[0;34m(self, x, y, w)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0myi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0my_class\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mtemp_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPsi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPsi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3e81ec34c36e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mPsi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3e81ec34c36e>\u001b[0m in \u001b[0;36mfeatureMap\u001b[0;34m(X, y, num_classes)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfeature_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_outFeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfeature_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[1;31m#feature_map[y*2+1] = X[1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "#the following code tests the MulticlassSVM and sgd\n",
    "#will fail if MulticlassSVM is not implemented yet\n",
    "est = MulticlassSVM(6,lam=1)\n",
    "est.fit(X,y)\n",
    "print(\"w:\")\n",
    "print(est.coef_)\n",
    "Z = est.predict(mesh_input)\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y, est.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
